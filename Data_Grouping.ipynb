{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cokzrk1-eSAH"
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaPN1Us8eSAL"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "result = pd.read_csv(\"okcupid_profiles_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5hhIiaVeSAM"
   },
   "outputs": [],
   "source": [
    "# create new dataframe\n",
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform or Remain unchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtqNdhCSeSAM"
   },
   "outputs": [],
   "source": [
    "# add columns to new dataframe\n",
    "new_df[['age', 'status', 'sex', 'orientation','body_type'] ] = result[['age', 'status', 'sex', 'orientation', 'body_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCVzLckheSAN"
   },
   "outputs": [],
   "source": [
    "# create new column for diet\n",
    "new_df['diet'] = result['diet'].apply(lambda x: 'anything' if 'anything' in x\n",
    "                                   else 'vegetarian' if ('vegetarian' in x or 'vegan' in x)\n",
    "                                   else 'halal' if 'halal' in x\n",
    "                                   else 'kosher' if 'kosher' in x\n",
    "                                   else 'other')\n",
    "# create new column for drinks\n",
    "new_df[['drinks', 'drugs']] = result [['drinks', 'drugs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beXZnn8TeSAN"
   },
   "outputs": [],
   "source": [
    "# create new column for education\n",
    "dict_education = {\n",
    "    'working on college/university': 'college',\n",
    "    'graduated from college/university': 'college',\n",
    "    'working on two-year college': 'college',\n",
    "    'college/university': 'college',\n",
    "    'two-year college': 'college',\n",
    "    'graduated from two-year college': 'college',\n",
    "    'dropped out of college/university': 'college',\n",
    "    'dropped out of two-year college': 'college',\n",
    "    'graduated from masters program': 'master',\n",
    "    'working on masters program': 'master',\n",
    "    'masters program': 'master',\n",
    "    'dropped out of masters program': 'master',\n",
    "    'graduated from ph.d program': 'phd',\n",
    "    'working on ph.d program': 'phd',\n",
    "    'dropped out of ph.d program': 'phd',\n",
    "    'ph.d program': 'phd',\n",
    "    'graduated from law school': 'law_school',\n",
    "    'working on law school': 'law_school',\n",
    "    'law school': 'law_school',\n",
    "    'dropped out of law school': 'law_school',\n",
    "    'working on space camp': 'space_camp',\n",
    "    'graduated from space camp': 'space_camp',\n",
    "    'dropped out of space camp': 'space_camp',\n",
    "    'space camp': 'space_camp',\n",
    "    'working on med school': 'med_school',\n",
    "    'graduated from med school': 'med_school',\n",
    "    'dropped out of med school': 'med_school',\n",
    "    'med school': 'med_school',\n",
    "    'graduated from high school': 'high_school',\n",
    "    'dropped out of high school': 'high_school',\n",
    "    'working on high school': 'high_school',\n",
    "    'high school': 'high_school'}\n",
    "\n",
    "# map education\n",
    "def map_education(education):\n",
    "    for key, value in dict_education.items():\n",
    "        if education in key:\n",
    "            return value\n",
    "    return 'other'\n",
    "\n",
    "# create new column for education\n",
    "new_df['education'] = result['education'].apply(map_education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AVRur_NeSAN"
   },
   "outputs": [],
   "source": [
    "# split ethnicity into multiple columns\n",
    "ethnicity_split_series = pd.Series(result['ethnicity'].unique()).dropna().str.split(', ', expand=True)\n",
    "# get all parts\n",
    "ethnicity_all_parts = pd.Series(ethnicity_split_series.values.ravel()).dropna()\n",
    "# get unique values\n",
    "ethnicity_unique_series = ethnicity_all_parts.drop_duplicates().reset_index(drop=True)\n",
    "# create a list of unique values\n",
    "ethnicity_list = ethnicity_unique_series.tolist()\n",
    "# create new columns for ethnicity\n",
    "for ethnicity in ethnicity_list:\n",
    "    new_df[f'{ethnicity}'] = result['ethnicity'].apply(lambda x: 1 if pd.notna(x) and ethnicity in x else 0) # 'yes' =1,'no' =0\n",
    "\n",
    "# create new column for height in cm\n",
    "new_df['height (cm)'] = result.height.apply(lambda x: round(x * 2.54, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHypwQs1eSAN"
   },
   "outputs": [],
   "source": [
    "# create new column for income\n",
    "new_df['job'] = result['job'].apply(lambda x: 'other' if 'rather not say' in x else x)\n",
    "\n",
    "# create new columns for location\n",
    "new_df[['city', 'state', 'country']] = result['location'].str.split(', ', n=2, expand=True)\n",
    "# create new column for country\n",
    "us_states = [\"alabama\", \"alaska\", \"arizona\", \"arkansas\", \"california\", \"colorado\", \"connecticut\",\n",
    "                     \"delaware\", \"florida\", \"georgia\", \"hawaii\", \"idaho\", \"illinois\", \"indiana\", \"iowa\",\n",
    "                     \"kansas\", \"kentucky\", \"louisiana\", \"maine\", \"maryland\", \"massachusetts\", \"michigan\",\n",
    "                     \"minnesota\", \"mississippi\", \"missouri\", \"montana\", \"nebraska\", \"nevada\", \"new hampshire\",\n",
    "                     \"new jersey\", \"new mexico\", \"new york\", \"north carolina\", \"north dakota\", \"ohio\", \"oklahoma\",\n",
    "                     \"oregon\", \"pennsylvania\", \"rhode island\", \"south carolina\", \"south dakota\", \"tennessee\",\n",
    "                     \"texas\", \"utah\", \"vermont\", \"virginia\", \"washington\", \"west virginia\", \"wisconsin\", \"wyoming\", 'district of columbia']\n",
    "# create new column for country\n",
    "new_df['country'] = new_df['state'].apply(lambda x : 'canada' if x == 'british columbia' else x if x not in us_states else 'united states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3TL92zmeSAO"
   },
   "outputs": [],
   "source": [
    "# create new column for kids\n",
    "new_df['has kids'] = result['offspring'].apply(lambda x: 'yes' if pd.notna(x) and ('has kids' in x or 'has a kid' in x)\n",
    "                                       else 'no')\n",
    "new_df['wants kids'] = result['offspring'].apply(lambda x: 'no' if pd.notna(x) and \"doesn't want\" in x\n",
    "                                         else 'yes' if pd.notna(x) and ('want them' in x or 'wants them' in x or\n",
    "                                                                               'want more' in x or 'wants more' in x or\n",
    "                                                                                'want kids' in x or 'wants kids' in x)\n",
    "                                                                                else 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXaLP3oweSAO"
   },
   "outputs": [],
   "source": [
    "# create new column for pets\n",
    "new_df['dogs lovers'] = result['pets'].apply(lambda x: 'yes' if pd.notna(x) and 'dislikes dogs' in x\n",
    "                                     else 'no' if pd.notna(x) and ('likes dogs' in x or 'has dogs' in x)\n",
    "                                     else 'neutral')\n",
    "new_df['cats lovers'] = result['pets'].apply(lambda x: 'no' if pd.notna(x) and 'dislikes cats' in x\n",
    "                                    else 'yes' if pd.notna(x) and ('likes cats' in x or 'has cats' in x)\n",
    "                                    else 'neutral')\n",
    "new_df['dogs owners'] = result['pets'].apply(lambda x: 'yes' if pd.notna(x) and 'has dogs' in x else 'no')\n",
    "new_df['cats owners'] = result['pets'].apply(lambda x: 'yes' if pd.notna(x) and 'has cats' in x else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6jcV6XTeSAO"
   },
   "outputs": [],
   "source": [
    "# create new column for sign\n",
    "result[['sign_1', 'sign_attitude']] = result['sign'].str.split(' ', n=1, expand=True)\n",
    "# create new column for religion\n",
    "result[['religion_1', 'religion_attitude']] = result['religion'].str.split(' ', n=1, expand=True)\n",
    "# drop attidude columns\n",
    "result = result.drop(columns=['sign_attitude', 'religion_attitude'])\n",
    "# add columns to new dataframe\n",
    "new_df[['sign','religion']] = result[['sign_1', 'religion_1']]\n",
    "# drop sign_1 and religion_1\n",
    "result = result.drop(columns=['sign_1', 'religion_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adcwHlfleSAO"
   },
   "outputs": [],
   "source": [
    "# create new column for smokes\n",
    "new_df['smokes'] = result['smokes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkpz1DANeSAO",
    "outputId": "94f12523-fd7f-4a61-e2c7-ef0368ba28d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n",
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\3392638732.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()\n"
     ]
    }
   ],
   "source": [
    "# create new column for speaks\n",
    "speaks_split_series = pd.Series(result['speaks'].unique()).str.split(', ', expand=True)\n",
    "# get all parts\n",
    "speaks_all_parts = pd.Series(speaks_split_series.values.ravel()).dropna()\n",
    "# get unique values\n",
    "speaks_unique_series = speaks_all_parts.drop_duplicates().reset_index(drop=True)\n",
    "# create a list of unique values\n",
    "language_list = speaks_unique_series.tolist()\n",
    "# create new columns for speaks\n",
    "first_words = [lang.split()[0] for lang in language_list]\n",
    "# remove duplicates\n",
    "language_list= list(set(first_words))\n",
    "\n",
    "# create new columns for speaks\n",
    "for language in language_list:\n",
    "    new_df[f'{language} speaks'] = result['speaks'].apply(lambda x: 1 if pd.notna(x) and language in x else 0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFT3C7U1eSAP",
    "outputId": "d48b5652-7f22-4224-dcc9-f3109e788a70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seacc\\AppData\\Local\\Temp\\ipykernel_10052\\1603773799.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['essay_all']= result['essay_all'].copy()\n"
     ]
    }
   ],
   "source": [
    "# create new column for essay_all\n",
    "new_df['essay_all']= result['essay_all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEdl1m6AeSAP",
    "outputId": "14175f08-269a-4d20-a0c1-3be55d58685c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'asian',\n",
       "       ...\n",
       "       'turkish speaks', 'mongolian speaks', 'persian speaks', 'hindi speaks',\n",
       "       'norwegian speaks', 'italian speaks', 'estonian speaks',\n",
       "       'hawaiian speaks', 'sardinian speaks', 'essay_all'],\n",
       "      dtype='object', length=110)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checikng columns\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Grouped Dataset as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0z9kE6VeSAP"
   },
   "outputs": [],
   "source": [
    "# save new dataframe\n",
    "new_df.to_csv('okcupid_profiles_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

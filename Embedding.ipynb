{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51c0a5c",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2c353e-d640-4d42-932b-0dd3f95392a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# show progress bar\n",
    "from tqdm.auto import tqdm\n",
    "# embedding\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b54125-7a52-4f26-aa5b-c24c8b454807",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c314a1-21ec-4f0e-9202-1eb6218389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from the output of \"Data Cleanse.ipynb\"\n",
    "df = pd.read_csv(\"okcupid_profiles_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483a7bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>job</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>essay_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>190.0</td>\n",
       "      <td>transportation</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>178.0</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>available</td>\n",
       "      <td>male</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>black, native american, pacific islander, white</td>\n",
       "      <td>173.0</td>\n",
       "      <td>other</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>no kids and neutral to kids</td>\n",
       "      <td>has cats</td>\n",
       "      <td>irreligion</td>\n",
       "      <td>pisces but it doesn't matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>180.0</td>\n",
       "      <td>student</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>irreligion</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>i work in a library and go to school. . .,read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>168.0</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>no kids and neutral to kids</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>irreligion</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     status   sex orientation       body_type               diet  \\\n",
       "0  22.0     single  male    straight  a little extra  strictly anything   \n",
       "1  35.0     single  male    straight         average       mostly other   \n",
       "2  38.0  available  male    straight            thin           anything   \n",
       "3  23.0     single  male    straight            thin         vegetarian   \n",
       "4  29.0     single  male    straight        athletic           anything   \n",
       "\n",
       "     drinks      drugs                          education  \\\n",
       "0  socially      never      working on college/university   \n",
       "1     often  sometimes              working on space camp   \n",
       "2  socially      never     graduated from masters program   \n",
       "3  socially      never      working on college/university   \n",
       "4  socially      never  graduated from college/university   \n",
       "\n",
       "                                         ethnicity  height  \\\n",
       "0                                     asian, white   190.0   \n",
       "1                                            white   178.0   \n",
       "2  black, native american, pacific islander, white   173.0   \n",
       "3                                            white   180.0   \n",
       "4                              asian, black, other   168.0   \n",
       "\n",
       "                           job                         location  \\\n",
       "0               transportation  south san francisco, california   \n",
       "1         hospitality / travel              oakland, california   \n",
       "2                        other        san francisco, california   \n",
       "3                      student             berkeley, california   \n",
       "4  artistic / musical / writer        san francisco, california   \n",
       "\n",
       "                                offspring                       pets  \\\n",
       "0  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2             no kids and neutral to kids                   has cats   \n",
       "3                       doesn't want kids                 likes cats   \n",
       "4             no kids and neutral to kids  likes dogs and likes cats   \n",
       "\n",
       "                                   religion                          sign  \\\n",
       "0     agnosticism and very serious about it                        gemini   \n",
       "1  agnosticism but not too serious about it                        cancer   \n",
       "2                                irreligion  pisces but it doesn't matter   \n",
       "3                                irreligion                        pisces   \n",
       "4                                irreligion                      aquarius   \n",
       "\n",
       "      smokes                                             speaks  \\\n",
       "0  sometimes                                            english   \n",
       "1         no  english (fluently), spanish (poorly), french (...   \n",
       "2         no                               english, french, c++   \n",
       "3         no                           english, german (poorly)   \n",
       "4         no                                            english   \n",
       "\n",
       "                                           essay_all  \n",
       "0  about me:  i would love to think that i was so...  \n",
       "1  i am a chef: this is what that means. 1. i am ...  \n",
       "2  i'm not ashamed of much, but writing public te...  \n",
       "3  i work in a library and go to school. . .,read...  \n",
       "4  hey how's it going? currently vague on the pro...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f7e08",
   "metadata": {},
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f427cf",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6012225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demographic_sentence(row):\n",
    "    \"\"\"\n",
    "    Convert a user's demographic data into a long descriptive sentence.\n",
    "    \"\"\"\n",
    "    # Fill missing values with placeholders\n",
    "    sex = row['sex'] if pd.notna(row['sex']) else \"a person\"\n",
    "    status = row['status'] if pd.notna(row['status']) else \"an unspecified relationship status\"\n",
    "    orientation = row['orientation'] if pd.notna(row['orientation']) else \"with an unspecified orientation\"\n",
    "    body_type = row['body_type'] if pd.notna(row['body_type']) else \"an unspecified body type\"\n",
    "    education = row['education'] if pd.notna(row['education']) else \"an unspecified education level\"\n",
    "    job = row['job'] if pd.notna(row['job']) else \"no specific job mentioned\"\n",
    "    location = row['location'] if pd.notna(row['location']) else \"an unspecified location\"\n",
    "    ethnicity = row['ethnicity'] if pd.notna(row['ethnicity']) else \"an unspecified ethnicity\"\n",
    "    diet = row['diet'] if pd.notna(row['diet']) else \"no specific diet preference\"\n",
    "    drinks = row['drinks'] if pd.notna(row['drinks']) else \"an unspecified drinking habit\"\n",
    "    smokes = row['smokes'] if pd.notna(row['smokes']) else \"an unspecified smoking habit\"\n",
    "    drugs = row['drugs'] if pd.notna(row['drugs']) else \"an unspecified stance on drugs\"\n",
    "    pets = row['pets'] if pd.notna(row['pets']) else \"no specific pet preference\"\n",
    "    religion = row['religion'] if pd.notna(row['religion']) else \"no specific religion\"\n",
    "    sign = row['sign'] if pd.notna(row['sign']) else \"no zodiac sign mentioned\"\n",
    "    speaks = row['speaks'] if pd.notna(row['speaks']) else \"an unspecified language proficiency\"\n",
    "\n",
    "    # Construct the long descriptive sentence\n",
    "    sentence = (f\"{sex}, {status}, living in {location}, sexual orientation is {orientation}. \"\n",
    "                f\"Has {body_type} body type and ethnicity is {ethnicity}. \"\n",
    "                f\"Education level: {education}. industry: {job}. \"\n",
    "                f\"Dietary preference: {diet}. Drinking habit: {drinks}. \"\n",
    "                f\"Smoking habit: {smokes}. Drug use: {drugs}. \"\n",
    "                f\"Pet preference: {pets}. Religion: {religion}. Zodiac sign: {sign}. \"\n",
    "                f\"Speaks: {speaks}.\")\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Generate demographic sentences for each user\n",
    "def combine_demographics_essay(row):\n",
    "    \"\"\"\n",
    "    Combine demographic data and essay data into a single sentence.\n",
    "    \"\"\"\n",
    "    # Generate demographic sentence\n",
    "    demographic_sentence = generate_demographic_sentence(row)\n",
    "    # extract essay data and fill missing values with empty string\n",
    "    essay = row['essay_all'] if pd.notna(row['essay_all']) else \"\"\n",
    "    # Combine demographic sentence and essay data\n",
    "    sentence = demographic_sentence + \" \" + essay\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193f8c5",
   "metadata": {},
   "source": [
    "## Convert text to embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b3684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(df, model):\n",
    "    \"\"\"\n",
    "    Generate sentence embeddings for all user profiles in the dataset.\n",
    "    \"\"\"\n",
    "    # Combine demographic data and essay data into a single sentence\n",
    "    sentences = df.apply(combine_demographics_essay, axis=1).tolist()\n",
    "\n",
    "    # Generate sentence embeddings\n",
    "    embeddings = model.encode(sentences, show_progress_bar=True)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a4bc9",
   "metadata": {},
   "source": [
    "## Standarize Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2c0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_numeric(df):\n",
    "    \"\"\"\n",
    "    Standardize non-text features in the dataset.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df = df.copy()\n",
    "    # Standardize numeric features for float64 and int64 data types\n",
    "    for col in df.columns:\n",
    "        if (df[col].dtype == 'float64') or (df[col].dtype == 'int64'):\n",
    "            # Standardize the column by subtracting the median and dividing by the standard deviation\n",
    "            df[col] = (df[col] - df[col].median()) / df[col].std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eaa13b",
   "metadata": {},
   "source": [
    "## Combine All Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15524de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, model):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by generating embeddings and standardizing non-text features.\n",
    "    \"\"\"\n",
    "    # Generate embeddings\n",
    "    embeddings = generate_embeddings(df, model)\n",
    "    \n",
    "    # Standardize non-text features\n",
    "    non_text_features = df.select_dtypes(include=['float64', 'int64'])\n",
    "    non_text_features_standardized = standardize_numeric(non_text_features)\n",
    "    \n",
    "    # Concatenate the embeddings and non-text features\n",
    "    X = np.concatenate([embeddings, non_text_features_standardized], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d57d57",
   "metadata": {},
   "source": [
    "# Perform Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448642dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6620fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c205d10e535a457d93e34c5f13a671b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "preprocess_data = preprocess_data(df, sbert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95321481",
   "metadata": {},
   "source": [
    "# Save preprocessed as .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da9f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data to a file.\n",
    "np.save(\"okcupid_profiles_preprocessed.npy\", preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a194d550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the preprocessed data is saved correctly\n",
    "(np.load(\"okcupid_profiles_preprocessed.npy\") == preprocess_data).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>...</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vibrant, expressive, caring optimist. i love b...</td>\n",
       "      <td>the happiest times have been when life came to...</td>\n",
       "      <td>i make an outstanding osso bucco. i am also ve...</td>\n",
       "      <td>i am told that people notice my smile, eyes an...</td>\n",
       "      <td>i am an avid movie watcher and follow the broa...</td>\n",
       "      <td>my family, my dog, italy, words and music!</td>\n",
       "      <td>writing my book.</td>\n",
       "      <td>running with my dog, finishing up the work wee...</td>\n",
       "      <td>i have a dream to sing at the alconquin in nyc...</td>\n",
       "      <td>you are seeking a long term connection of shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white, other</td>\n",
       "      <td>...</td>\n",
       "      <td>i'm nick. i never know what to write about mys...</td>\n",
       "      <td>currently finishing school for film production...</td>\n",
       "      <td>filmmaking, photography, graphic design, web d...</td>\n",
       "      <td>dude, i don't know.</td>\n",
       "      <td>movies: hook (the greatest adventure ever!), g...</td>\n",
       "      <td>iphone contact lenses headphones camera tv rem...</td>\n",
       "      <td>i do most of my thinking on the bus to/from wo...</td>\n",
       "      <td>bringin' home bacon, or drinking and shakin'!</td>\n",
       "      <td>when i was 18 i got a tattoo of waldo somewher...</td>\n",
       "      <td>meh if you made it this far you might as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>...</td>\n",
       "      <td>hello! i enjoy traveling, watching movies, and...</td>\n",
       "      <td>i'm a civil engineer, who enjoys helping the c...</td>\n",
       "      <td>- looking at things objectively - getting thin...</td>\n",
       "      <td>i'm quiet until i get used to the environment ...</td>\n",
       "      <td>last book: \"game change\". movies: bourne serie...</td>\n",
       "      <td>- iphone - friends and family - internet - bay...</td>\n",
       "      <td>aside from work, how to improve my home.</td>\n",
       "      <td>out enjoying friendly conversation over dinner.</td>\n",
       "      <td>please let me think about this more.</td>\n",
       "      <td>we have similar interests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>...</td>\n",
       "      <td>\"all i have in this world are my balls and my ...</td>\n",
       "      <td>following my dreams... \"you got a dream... you...</td>\n",
       "      <td>listening</td>\n",
       "      <td>it used to be the hair until i mowed it off bu...</td>\n",
       "      <td>where to begin musically: right now i listen t...</td>\n",
       "      <td>music, family, friends, a basketball, hoop, so...</td>\n",
       "      <td>what can i do to make someone chuckle....</td>\n",
       "      <td>what i would do on any other day. everydays a ...</td>\n",
       "      <td>i like walking around in other people's house ...</td>\n",
       "      <td>you are interested and interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>gay</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>is it odd that having a little \"enemy\" status ...</td>\n",
       "      <td>i work with elderly people (psychotherapy and ...</td>\n",
       "      <td>i'm a great bullshitter. i don't know what it ...</td>\n",
       "      <td>either that i am funny/sarcastic, or that i am...</td>\n",
       "      <td>i just read the help by kathryn stockett, sooo...</td>\n",
       "      <td>1. family &amp; friends &amp; other humans - interacti...</td>\n",
       "      <td>sex, myself, other people, how amazing everyth...</td>\n",
       "      <td>out at happy hour with my friends, running int...</td>\n",
       "      <td>i wish i could cry like holly hunter in broadc...</td>\n",
       "      <td>if you have a back-bone, an opinion, a sense o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     status sex orientation       body_type               diet  \\\n",
       "0       22     single   m    straight  a little extra  strictly anything   \n",
       "1       35     single   m    straight         average       mostly other   \n",
       "2       38  available   m    straight            thin           anything   \n",
       "3       23     single   m    straight            thin         vegetarian   \n",
       "4       29     single   m    straight        athletic                NaN   \n",
       "...    ...        ...  ..         ...             ...                ...   \n",
       "59941   59     single   f    straight             NaN                NaN   \n",
       "59942   24     single   m    straight             fit    mostly anything   \n",
       "59943   42     single   m    straight         average    mostly anything   \n",
       "59944   27     single   m    straight        athletic    mostly anything   \n",
       "59945   39     single   m         gay         average                NaN   \n",
       "\n",
       "           drinks      drugs                          education  \\\n",
       "0        socially      never      working on college/university   \n",
       "1           often  sometimes              working on space camp   \n",
       "2        socially        NaN     graduated from masters program   \n",
       "3        socially        NaN      working on college/university   \n",
       "4        socially      never  graduated from college/university   \n",
       "...           ...        ...                                ...   \n",
       "59941    socially      never  graduated from college/university   \n",
       "59942       often  sometimes      working on college/university   \n",
       "59943  not at all      never     graduated from masters program   \n",
       "59944    socially      often      working on college/university   \n",
       "59945    socially        NaN     graduated from masters program   \n",
       "\n",
       "                 ethnicity  ...  \\\n",
       "0             asian, white  ...   \n",
       "1                    white  ...   \n",
       "2                      NaN  ...   \n",
       "3                    white  ...   \n",
       "4      asian, black, other  ...   \n",
       "...                    ...  ...   \n",
       "59941                  NaN  ...   \n",
       "59942         white, other  ...   \n",
       "59943                asian  ...   \n",
       "59944         asian, black  ...   \n",
       "59945                white  ...   \n",
       "\n",
       "                                                  essay0  \\\n",
       "0      about me:  i would love to think that i was so...   \n",
       "1      i am a chef: this is what that means. 1. i am ...   \n",
       "2      i'm not ashamed of much, but writing public te...   \n",
       "3              i work in a library and go to school. . .   \n",
       "4      hey how's it going? currently vague on the pro...   \n",
       "...                                                  ...   \n",
       "59941  vibrant, expressive, caring optimist. i love b...   \n",
       "59942  i'm nick. i never know what to write about mys...   \n",
       "59943  hello! i enjoy traveling, watching movies, and...   \n",
       "59944  \"all i have in this world are my balls and my ...   \n",
       "59945  is it odd that having a little \"enemy\" status ...   \n",
       "\n",
       "                                                  essay1  \\\n",
       "0      currently working as an international agent fo...   \n",
       "1      dedicating everyday to being an unbelievable b...   \n",
       "2      i make nerdy software for musicians, artists, ...   \n",
       "3              reading things written by old dead people   \n",
       "4                             work work work work + play   \n",
       "...                                                  ...   \n",
       "59941  the happiest times have been when life came to...   \n",
       "59942  currently finishing school for film production...   \n",
       "59943  i'm a civil engineer, who enjoys helping the c...   \n",
       "59944  following my dreams... \"you got a dream... you...   \n",
       "59945  i work with elderly people (psychotherapy and ...   \n",
       "\n",
       "                                                  essay2  \\\n",
       "0      making people laugh. ranting about a good salt...   \n",
       "1      being silly. having ridiculous amonts of fun w...   \n",
       "2      improvising in different contexts. alternating...   \n",
       "3      playing synthesizers and organizing books acco...   \n",
       "4      creating imagery to look at: http://bagsbrown....   \n",
       "...                                                  ...   \n",
       "59941  i make an outstanding osso bucco. i am also ve...   \n",
       "59942  filmmaking, photography, graphic design, web d...   \n",
       "59943  - looking at things objectively - getting thin...   \n",
       "59944                                          listening   \n",
       "59945  i'm a great bullshitter. i don't know what it ...   \n",
       "\n",
       "                                                  essay3  \\\n",
       "0      the way i look. i am a six foot half asian, ha...   \n",
       "1                                                    NaN   \n",
       "2      my large jaw and large glasses are the physica...   \n",
       "3                      socially awkward but i do my best   \n",
       "4                i smile a lot and my inquisitive nature   \n",
       "...                                                  ...   \n",
       "59941  i am told that people notice my smile, eyes an...   \n",
       "59942                                dude, i don't know.   \n",
       "59943  i'm quiet until i get used to the environment ...   \n",
       "59944  it used to be the hair until i mowed it off bu...   \n",
       "59945  either that i am funny/sarcastic, or that i am...   \n",
       "\n",
       "                                                  essay4  \\\n",
       "0      books: absurdistan, the republic, of mice and ...   \n",
       "1      i am die hard christopher moore fan. i don't r...   \n",
       "2      okay this is where the cultural matrix gets so...   \n",
       "3      bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4      music: bands, rappers, musicians at the moment...   \n",
       "...                                                  ...   \n",
       "59941  i am an avid movie watcher and follow the broa...   \n",
       "59942  movies: hook (the greatest adventure ever!), g...   \n",
       "59943  last book: \"game change\". movies: bourne serie...   \n",
       "59944  where to begin musically: right now i listen t...   \n",
       "59945  i just read the help by kathryn stockett, sooo...   \n",
       "\n",
       "                                                  essay5  \\\n",
       "0                      food. water. cell phone. shelter.   \n",
       "1      delicious porkness in all of its glories. my b...   \n",
       "2      movement conversation creation contemplation t...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941         my family, my dog, italy, words and music!   \n",
       "59942  iphone contact lenses headphones camera tv rem...   \n",
       "59943  - iphone - friends and family - internet - bay...   \n",
       "59944  music, family, friends, a basketball, hoop, so...   \n",
       "59945  1. family & friends & other humans - interacti...   \n",
       "\n",
       "                                                  essay6  \\\n",
       "0                            duality and humorous things   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                             cats and german philosophy   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941                                   writing my book.   \n",
       "59942  i do most of my thinking on the bus to/from wo...   \n",
       "59943           aside from work, how to improve my home.   \n",
       "59944          what can i do to make someone chuckle....   \n",
       "59945  sex, myself, other people, how amazing everyth...   \n",
       "\n",
       "                                                  essay7  \\\n",
       "0      trying to find someone to hang out with. i am ...   \n",
       "1                                                    NaN   \n",
       "2      viewing. listening. dancing. talking. drinking...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  running with my dog, finishing up the work wee...   \n",
       "59942      bringin' home bacon, or drinking and shakin'!   \n",
       "59943    out enjoying friendly conversation over dinner.   \n",
       "59944  what i would do on any other day. everydays a ...   \n",
       "59945  out at happy hour with my friends, running int...   \n",
       "\n",
       "                                                  essay8  \\\n",
       "0      i am new to california and looking for someone...   \n",
       "1      i am very open and will share just about anyth...   \n",
       "2      when i was five years old, i was known as \"the...   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59941  i have a dream to sing at the alconquin in nyc...   \n",
       "59942  when i was 18 i got a tattoo of waldo somewher...   \n",
       "59943               please let me think about this more.   \n",
       "59944  i like walking around in other people's house ...   \n",
       "59945  i wish i could cry like holly hunter in broadc...   \n",
       "\n",
       "                                                  essay9  \n",
       "0      you want to be swept off your feet! you are ti...  \n",
       "1                                                    NaN  \n",
       "2      you are bright, open, intense, silly, ironic, ...  \n",
       "3                                  you feel so inclined.  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "59941  you are seeking a long term connection of shar...  \n",
       "59942     meh if you made it this far you might as well.  \n",
       "59943                         we have similar interests.  \n",
       "59944              you are interested and interesting...  \n",
       "59945  if you have a back-bone, an opinion, a sense o...  \n",
       "\n",
       "[59946 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height          income\n",
       "count  59946.000000  59943.000000    59946.000000\n",
       "mean      32.340290     68.295281    20033.222534\n",
       "std        9.452779      3.994803    97346.192104\n",
       "min       18.000000      1.000000       -1.000000\n",
       "25%       26.000000     66.000000       -1.000000\n",
       "50%       30.000000     68.000000       -1.000000\n",
       "75%       37.000000     71.000000       -1.000000\n",
       "max      110.000000     95.000000  1000000.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
       "       'smokes', 'speaks', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
       "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_body_type = {\n",
    "    'a little extra': 'fat',\n",
    "    'full figured': 'fat',\n",
    "    'overweight': 'fat',\n",
    "    'curvey': 'fat',\n",
    "    'used up': 'fat',\n",
    "    'average': 'average',\n",
    "    'athletic': 'average',\n",
    "    'fit': 'average',\n",
    "    'jacked': 'average',\n",
    "    'thin': 'thin',\n",
    "    'skinny': 'thin',\n",
    "    'rather not say': 'other'}\n",
    "\n",
    "dict_drinks = {\n",
    "    'not at all': 'no',\n",
    "    'rarely': 'no',\n",
    "    'socially': 'sometimes',\n",
    "    'desperately': 'sometimes',\n",
    "    'often': 'often',\n",
    "    'very often': 'often'}\n",
    "\n",
    "dict_education = {\n",
    "    'working on college/university': 'college',\n",
    "    'graduated from college/university': 'college',\n",
    "    'working on two-year college': 'college',\n",
    "    'college/university': 'college',\n",
    "    'two-year college': 'college',\n",
    "    'graduated from two-year college': 'college',\n",
    "    'dropped out of college/university': 'college',\n",
    "    'dropped out of two-year college': 'college',\n",
    "    'graduated from masters program': 'master',\n",
    "    'working on masters program': 'master',\n",
    "    'masters program': 'master',\n",
    "    'dropped out of masters program': 'master',\n",
    "    'graduated from ph.d program': 'phd',\n",
    "    'working on ph.d program': 'phd',\n",
    "    'dropped out of ph.d program': 'phd',\n",
    "    'ph.d program': 'phd',\n",
    "    'graduated from law school': 'law_school',\n",
    "    'working on law school': 'law_school',\n",
    "    'law school': 'law_school',\n",
    "    'dropped out of law school': 'law_school',\n",
    "    'working on space camp': 'space_camp',\n",
    "    'graduated from space camp': 'space_camp',\n",
    "    'dropped out of space camp': 'space_camp',\n",
    "    'space camp': 'space_camp',\n",
    "    'working on med school': 'med_school',\n",
    "    'graduated from med school': 'med_school',\n",
    "    'dropped out of med school': 'med_school',\n",
    "    'med school': 'med_school',\n",
    "    'graduated from high school': 'high_school',\n",
    "    'dropped out of high school': 'high_school',\n",
    "    'working on high school': 'high_school',\n",
    "    'high school': 'high_school'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df.copy()\n",
    "    df['status'] = df['status'].apply(lambda x: 'married' if x == 'married' else 'single')\n",
    "    df['body_type'] = df['body_type'].map(dict_body_type).fillna('other')\n",
    "    df['diet'] = df['diet'].fillna('anything').str.replace('mostly ','').str.replace('strictly ','').apply(lambda x: 'vegetarian' if x == 'vegan' else x)\n",
    "    df['drinks'] = df['drinks'].map(dict_drinks).fillna('no')\n",
    "    df['drugs'] = df['drugs'].fillna('never')\n",
    "    df['education'] = df['education'].map(dict_education)\n",
    "    df['height'] = df['height'].fillna(df['height'].median()).apply(lambda x: int(x * 2.54))\n",
    "    df[['city','region']] = df['location'].str.split(', ', expand=True).iloc[:,:2]\n",
    "    return df\n",
    "    \n",
    "# col need to fillna by KNN: education, job\n",
    "# col need to drop: income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "status             0\n",
       "sex                0\n",
       "orientation        0\n",
       "body_type       5296\n",
       "diet           24395\n",
       "drinks          2985\n",
       "drugs          14080\n",
       "education       6628\n",
       "ethnicity       5680\n",
       "height             3\n",
       "income             0\n",
       "job             8198\n",
       "last_online        0\n",
       "location           0\n",
       "offspring      35561\n",
       "pets           19921\n",
       "religion       20226\n",
       "sign           11056\n",
       "smokes          5512\n",
       "speaks            50\n",
       "essay0          5488\n",
       "essay1          7572\n",
       "essay2          9638\n",
       "essay3         11476\n",
       "essay4         10537\n",
       "essay5         10850\n",
       "essay6         13771\n",
       "essay7         12451\n",
       "essay8         19225\n",
       "essay9         12603\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
       "       'smokes', 'speaks', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
       "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of null value:  5680\n",
      "sum of value count:  54266\n",
      "ethnicity\n",
      "asian                                     6134\n",
      "asian, black                                59\n",
      "asian, black, hispanic / latin               2\n",
      "asian, black, hispanic / latin, other        2\n",
      "asian, black, hispanic / latin, white        2\n",
      "                                         ...  \n",
      "pacific islander, other                     14\n",
      "pacific islander, white                    156\n",
      "pacific islander, white, other              18\n",
      "white                                    32831\n",
      "white, other                               641\n",
      "Name: count, Length: 217, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = 'ethnicity'\n",
    "# print(df_clean:=clean(df)[col].value_counts().sort_index())\n",
    "# print('sum of null value: ', clean(df)[col].isnull().sum())\n",
    "# print('sum of value count: ', df_clean.sum())\n",
    "# print()\n",
    "df_raw = df[col].value_counts().sort_index()\n",
    "print('sum of null value: ', df[col].isnull().sum())\n",
    "print('sum of value count: ', df_raw.sum())\n",
    "print(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has kids'] = df['offspring'].apply(lambda x: 'has kid' if pd.notna(x) and ('has kids' in x or 'has a kid' in x)\n",
    "                                       else \"doesn't have kids\")\n",
    "df['wants kids'] = df['offspring'].apply(lambda x: \"doesn't wants kids\" if pd.notna(x) and \"doesn't want\" in x \n",
    "                                         else 'wants kids' if pd.notna(x) and ('want them' in x or 'wants them' in x or\n",
    "                                                                               'want more' in x or 'wants more' in x or\n",
    "                                                                                'want kids' in x or 'wants kids' in x)\n",
    "                                                                                else 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dogs lovers'] = df['pets'].apply(lambda x: 'dislikes dogs' if pd.notna(x) and 'dislikes dogs' in x \n",
    "                                     else 'likes dogs' if pd.notna(x) and ('likes dogs' in x or 'has dogs' in x) \n",
    "                                     else 'neutral')\n",
    "df['cats lovers'] = df['pets'].apply(lambda x: 'dislikes cats' if pd.notna(x) and 'dislikes cats' in x\n",
    "                                    else 'likes cats' if pd.notna(x) and ('likes cats' in x or 'has cats' in x) \n",
    "                                    else 'neutral')\n",
    "df['dogs owners'] = df['pets'].apply(lambda x: 'has cats' if pd.notna(x) and 'has dogs' in x else \"doesn't have dogs\")\n",
    "df['cats owners'] = df['pets'].apply(lambda x: 'has cats' if pd.notna(x) and 'has cats' in x else \"doesn't have dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sign_1', 'sign_attitude']] = df['sign'].str.split(' ', n=1, expand=True)\n",
    "df[['religion_1', 'religion_attitude']] = df['religion'].str.split(' ', n=1, expand=True)\n",
    "df = df.drop(columns=['sign_attitude', 'religion_attitude'])\n",
    "df['sign_1'] = df['sign_1'].fillna('other')\n",
    "df['religion_1'] = df['religion_1'].fillna('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['smokes_1'] = df['smokes'].fillna('no')\n",
    "df['smokes_1'] = df['smokes_1'].apply(lambda x: 'yes' if x != 'no' else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speaks_1'] = df['speaks'].fillna('other')\n",
    "speaks_split_series = pd.Series(df['speaks_1'].unique()).str.split(', ', expand=True)\n",
    "speaks_all_parts = pd.Series(speaks_split_series.values.ravel()).dropna()\n",
    "speaks_unique_series = speaks_all_parts.drop_duplicates().reset_index(drop=True)\n",
    "language_list = speaks_unique_series.tolist()\n",
    "first_words = [lang.split()[0] for lang in language_list]\n",
    "language_list= list(set(first_words))\n",
    "language_list\n",
    "df = df.drop(columns=['speaks_1'])\n",
    "for language in language_list:\n",
    "    df[f'{language} speaks'] = df['speaks'].apply(lambda x: 'yes' if pd.notna(x) and language in x else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ethnicity_1'] = df['ethnicity'].fillna('other')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n",
      "C:\\Users\\ben\\AppData\\Local\\Temp\\ipykernel_7400\\2928380256.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')\n"
     ]
    }
   ],
   "source": [
    "df['ethnicity_1'] = df['ethnicity'].fillna('other')\n",
    "ethnicity_split_series = pd.Series(df['ethnicity_1'].unique()).dropna().str.split(', ', expand=True)\n",
    "ethnicity_all_parts = pd.Series(ethnicity_split_series.values.ravel()).dropna()\n",
    "ethnicity_unique_series = ethnicity_all_parts.drop_duplicates().reset_index(drop=True)\n",
    "ethnicity_list = ethnicity_unique_series.tolist()\n",
    "df = df.drop(columns=['ethnicity_1'])\n",
    "for ethnicity in ethnicity_list:\n",
    "    df[f'{ethnicity}'] = df['ethnicity'].apply(lambda x: 'yes' if pd.notna(x) and ethnicity in x else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('okcupid_profiles_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
